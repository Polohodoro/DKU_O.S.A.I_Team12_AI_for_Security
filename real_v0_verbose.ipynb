{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 데이터 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile \n",
    "import pickle\n",
    "import pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pandas를 굳이 import하는 이유는 어차피 .pkl 파일 내에서 pandas.DataFrame 형식으로 저장되어 있어서 pandas가 없다면 pickle.load시에 문제가 생길 것이기에 미리 방지하기 위함입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Path('result.zip', '구매(수정)/'), Path('result.zip', '절도(수정)/')]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "archive=zipfile.ZipFile('result.zip')\n",
    "zroot=zipfile.Path(archive)\n",
    "list(zroot.iterdir())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Neck-RShoulder-x</th>\n",
       "      <th>Neck-RShoulder-y</th>\n",
       "      <th>Neck-LShoulder-x</th>\n",
       "      <th>Neck-LShoulder-y</th>\n",
       "      <th>RShoulder-RElbow-x</th>\n",
       "      <th>RShoulder-RElbow-y</th>\n",
       "      <th>RElbow-RWrist-x</th>\n",
       "      <th>RElbow-RWrist-y</th>\n",
       "      <th>LShoulder-LElbow-x</th>\n",
       "      <th>LShoulder-LElbow-y</th>\n",
       "      <th>...</th>\n",
       "      <th>RHip-RKnee-x</th>\n",
       "      <th>RHip-RKnee-y</th>\n",
       "      <th>RKnee-RAnkle-x</th>\n",
       "      <th>RKnee-RAnkle-y</th>\n",
       "      <th>Neck-LHip-x</th>\n",
       "      <th>Neck-LHip-y</th>\n",
       "      <th>LHip-LKnee-x</th>\n",
       "      <th>LHip-LKnee-y</th>\n",
       "      <th>LKnee-LAnkle-x</th>\n",
       "      <th>LKnee-LAnkle-y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.40794</td>\n",
       "      <td>0.913009</td>\n",
       "      <td>-0.509138</td>\n",
       "      <td>0.860685</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.40794</td>\n",
       "      <td>0.913009</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>300 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Neck-RShoulder-x  Neck-RShoulder-y  Neck-LShoulder-x  Neck-LShoulder-y  \\\n",
       "0                 0.0               0.0               0.0               0.0   \n",
       "1                 0.0               0.0               0.0               0.0   \n",
       "2                 0.0               0.0               0.0               0.0   \n",
       "3                 0.0               0.0               0.0               0.0   \n",
       "4                 0.0               0.0               0.0               0.0   \n",
       "..                ...               ...               ...               ...   \n",
       "295               0.0               0.0               0.0               0.0   \n",
       "296               0.0               0.0               0.0               0.0   \n",
       "297               0.0               0.0               0.0               0.0   \n",
       "298               0.0               0.0               0.0               0.0   \n",
       "299               0.0               0.0               0.0               0.0   \n",
       "\n",
       "     RShoulder-RElbow-x  RShoulder-RElbow-y  RElbow-RWrist-x  RElbow-RWrist-y  \\\n",
       "0                   0.0                 0.0              0.0              0.0   \n",
       "1                   0.0                 0.0              0.0              0.0   \n",
       "2                   0.0                 0.0              0.0              0.0   \n",
       "3                   0.0                 0.0              0.0              0.0   \n",
       "4                   0.0                 0.0              0.0              0.0   \n",
       "..                  ...                 ...              ...              ...   \n",
       "295                 0.0                 0.0              0.0              0.0   \n",
       "296                 0.0                 0.0              0.0              0.0   \n",
       "297                 0.0                 0.0              0.0              0.0   \n",
       "298                 0.0                 0.0              0.0              0.0   \n",
       "299                 0.0                 0.0              0.0              0.0   \n",
       "\n",
       "     LShoulder-LElbow-x  LShoulder-LElbow-y  ...  RHip-RKnee-x  RHip-RKnee-y  \\\n",
       "0                   0.0                 0.0  ...           0.0           0.0   \n",
       "1                   0.0                 0.0  ...           0.0           0.0   \n",
       "2                   0.0                 0.0  ...           0.0           0.0   \n",
       "3                   0.0                 0.0  ...           0.0           0.0   \n",
       "4                   0.0                 0.0  ...           0.0           0.0   \n",
       "..                  ...                 ...  ...           ...           ...   \n",
       "295                 0.0                 0.0  ...           0.0           0.0   \n",
       "296                 0.0                 0.0  ...           0.0           0.0   \n",
       "297                 0.0                 0.0  ...           0.0           0.0   \n",
       "298                 0.0                 0.0  ...           0.0           0.0   \n",
       "299                 0.0                 0.0  ...           0.0           0.0   \n",
       "\n",
       "     RKnee-RAnkle-x  RKnee-RAnkle-y  Neck-LHip-x  Neck-LHip-y  LHip-LKnee-x  \\\n",
       "0               0.0             0.0      0.00000     0.000000      0.000000   \n",
       "1               0.0             0.0     -0.40794     0.913009     -0.509138   \n",
       "2               0.0             0.0      0.00000     0.000000      0.000000   \n",
       "3               0.0             0.0      0.00000     0.000000      0.000000   \n",
       "4               0.0             0.0      0.00000     0.000000      0.000000   \n",
       "..              ...             ...          ...          ...           ...   \n",
       "295             0.0             0.0      0.00000     0.000000      0.000000   \n",
       "296             0.0             0.0      0.00000     0.000000      0.000000   \n",
       "297             0.0             0.0      0.00000     0.000000      0.000000   \n",
       "298             0.0             0.0      0.00000     0.000000      0.000000   \n",
       "299             0.0             0.0     -0.40794     0.913009      0.000000   \n",
       "\n",
       "     LHip-LKnee-y  LKnee-LAnkle-x  LKnee-LAnkle-y  \n",
       "0        0.000000             0.0             0.0  \n",
       "1        0.860685             0.0             0.0  \n",
       "2        0.000000             0.0             0.0  \n",
       "3        0.000000             0.0             0.0  \n",
       "4        0.000000             0.0             0.0  \n",
       "..            ...             ...             ...  \n",
       "295      0.000000             0.0             0.0  \n",
       "296      0.000000             0.0             0.0  \n",
       "297      0.000000             0.0             0.0  \n",
       "298      0.000000             0.0             0.0  \n",
       "299      0.000000             0.0             0.0  \n",
       "\n",
       "[300 rows x 24 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t1=next((zroot/'구매(수정)').iterdir())\n",
    "with t1.open('rb') as f:\n",
    "    df=pickle.load(f)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "device=torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dfs(myzip:zipfile.ZipFile,path:str):\n",
    "    mypath=zipfile.Path(myzip)/path\n",
    "    out=[]\n",
    "    for file in mypath.iterdir():\n",
    "        if file.suffix!='.pkl':\n",
    "            continue\n",
    "        try:\n",
    "            with file.open('rb') as f:\n",
    "                df=pickle.load(f)\n",
    "        except Exception:\n",
    "            import traceback\n",
    "            print('errer in file ',file)\n",
    "            traceback.print_exc()\n",
    "        df.to_numpy()\n",
    "        out.append(torch.tensor(df.to_numpy(),device=device,dtype=torch.float32))\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "gumaes=load_dfs(archive,'구매(수정)')\n",
    "juldos=load_dfs(archive,'절도(수정)')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "random.shuffle(gumaes)\n",
    "random.shuffle(juldos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({299, 300}, {179, 180})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{len(x) for x in gumaes},{len(x) for x in juldos}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "길이가 거의 동일하니, 그냥 gumaes는 299로, juldos는 179로 맞추려고 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "gumaes2=[(x if len(x)==299 else x[1:]) for x in gumaes ]\n",
    "gumaes2=torch.stack(gumaes2).contiguous()\n",
    "juldos2=[(x if len(x)==179 else x[1:]) for x in juldos ]\n",
    "juldos2=torch.stack(juldos2).contiguous()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({299}, {179})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{len(x) for x in gumaes2},{len(x) for x in juldos2}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 데이터 전처리 관련 유틸리티"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def random_forever(data):\n",
    "    mydata=list(data)\n",
    "    random.shuffle(mydata)\n",
    "    while True:\n",
    "        yield from mydata\n",
    "        random.shuffle(mydata)\n",
    "\n",
    "def batched(it,batchsize:int):\n",
    "    it=iter(it)\n",
    "    try:\n",
    "        while True:\n",
    "            yield [next(it) for _ in range(batchsize)]\n",
    "    except StopIteration:\n",
    "        pass\n",
    "def forever(x):\n",
    "    while True:\n",
    "        yield from x\n",
    "def sample_forever(data,batchsize):\n",
    "    #for datas in batched(random_forever(data),batchsize):\n",
    "    #    yield torch.nn.utils.rnn.pack_sequence(datas,enforce_sorted=False)\n",
    "    for indices in batched(random_forever(list(range(len(data)))),batchsize):\n",
    "        yield data.to(device)[torch.tensor(indices).to(device)]\n",
    "        #yield torch.stack(datas,1)\n",
    "    #for tups in batched(random_forever(data),batchsize):\n",
    "    #    X=torch.nn.utils.rnn.pack_sequence([x[0] for x in tups],enforce_sorted=False)\n",
    "    #    y=torch.tensor([i[1]for i in tups],dtype=torch.float32,device=device)\n",
    "    #    yield X,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.jit.script\n",
    "def get_loss(g_pred,j_pred,w_g:float=0.5):\n",
    "    return (((g_pred)**2).mean()*w_g+((1-j_pred)**2).mean()*(1-w_g))\n",
    "@torch.jit.script\n",
    "def get_acc(g_pred,j_pred,w_g):\n",
    "    return (torch.mean((g_pred<0.5),dtype=torch.float32)*w_g+torch.mean((j_pred>0.5),dtype=torch.float32).mean()*(1-w_g))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "여기서 절도 데이터는 한 데이터당 179프레임, 구매 데이터는 한 데이터당 299프레임으로 길이가 다르기 때문에, 굳이 패딩을 시도하기 보다는 각각 loss를 구한 뒤 그 loss를 합쳐서 새 loss를 만드는데, 이때 양쪽 다 단순한 mean을 써서 0.5:0.5로 섞이는 것을 방지하기 위해 loss를 구할 때 굳이 w_g를 두어 어느쪽 loss에 더 집중할지를 매 step마다 바뀌게 하여 overfit을 방지하고자 하였습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_by(x,p):\n",
    "    bound=int(len(x)*p)\n",
    "    return x[bound:],x[:bound]\n",
    "\n",
    "\n",
    "gumae_train,gumae_test=split_by(gumaes2,0.8)\n",
    "juldo_train,juldo_test=split_by(juldos2,0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 299, 24])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(torch.utils.data.DataLoader(gumae_test,batch_size=10))).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 모델 작성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import mylayers as mynn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "DROPOUT=0\n",
    "import torch.functional as F\n",
    "import itertools\n",
    "\n",
    "class MyModel(nn.Module):\n",
    "    def __init__(self,lstms,embedding,nomal):\n",
    "        super().__init__()\n",
    "        self.LSTMS=nn.ModuleList(lstms)\n",
    "        self.embedding=embedding\n",
    "        self.nomal=nomal\n",
    "        self.dropout=nn.Dropout(DROPOUT)\n",
    "    def forward(self,x,hxs=None):\n",
    "        if hxs is None:\n",
    "            hxs=itertools.repeat(None)\n",
    "            lasthx=None\n",
    "        else:\n",
    "            lasthx=hxs[-1]\n",
    "        newhxs=[]\n",
    "        for layer,hx in zip(self.LSTMS,hxs):\n",
    "            x,newhx=layer(x,hx)\n",
    "            x=self.dropout(torch.tanh(x))\n",
    "            newhxs.append(newhx)\n",
    "        x,newhx=self.embedding(x,lasthx)\n",
    "        newhxs.append(newhx)\n",
    "        x=self.nomal(x)\n",
    "\n",
    "        return x,tuple(newhxs)\n",
    "        \n",
    "\n",
    "\n",
    "tanh=nn.Tanh()\n",
    "relu=nn.ReLU()\n",
    "drop=nn.Dropout(DROPOUT)\n",
    "tanh=nn.Tanh()\n",
    "mymodel=MyModel(\n",
    "[\n",
    "    nn.LSTM(24,64),\n",
    "    nn.LSTM(64,128),\n",
    "    nn.LSTM(128,256),\n",
    "    nn.LSTM(256,256,num_layers=3),\n",
    "    \n",
    "],\n",
    "mynn.EmbeddingLSTM(256,128,dropout=DROPOUT)\n",
    ",\n",
    "nn.Sequential(\n",
    "    tanh,\n",
    "    nn.Linear(128,64),\n",
    "    relu,\n",
    "    drop,\n",
    "    nn.Linear(64,32),\n",
    "    drop,\n",
    "    relu,\n",
    "    nn.Linear(32,16),\n",
    "    drop,\n",
    "    relu,\n",
    "    nn.Linear(16,1),\n",
    "    nn.Sigmoid()\n",
    ")\n",
    ")\n",
    "\n",
    "mymodel=mymodel.to(device)\n",
    "optim=torch.optim.Adam(mymodel.parameters(),weight_decay=1e-4)\n",
    "\n",
    "sX=next(sample_forever(juldos2,20))\n",
    "mymodel_jit=torch.jit.trace(mymodel.forward,sX)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "매 프레임마다 받는 입력 크기가 24개이므로 첫 layer의 input_size는 24여야 합니다.\n",
    "\n",
    "모델 구조 자체는 LSTM들을 \n",
    "- nn.LSTM(24,64),\n",
    "- nn.LSTM(64,128),\n",
    "- nn.LSTM(128,256),\n",
    "- nn.LSTM(256,256,num_layers=3)\n",
    "순으로 쌓은 뒤에,\n",
    "- mynn.EmbeddingLSTM(256,128,dropout=DROPOUT)\n",
    "으로 LSTM(256,128)의 맨 마지막 출력만을 가져오고,\n",
    "\n",
    "그 뒤는 보이는 대로 모델을 쌓았습니다.\n",
    "\n",
    "마지막 layer에서는\n",
    "\n",
    "적당히 Linear,dropout,activation을 깔다가\n",
    "\n",
    "- nn.Linear(16,1)\n",
    "- nn.Sigmoid()\n",
    "\n",
    "\n",
    "마지막에는 원하는 출력값의 개수는 1이니 dim_hidden은 1로,\n",
    "\n",
    "출력값에서 절도면 1, 절도가 아니면 0을 원하니 0<출력값<1이 되게 하는 sigmoid을 맨 마지막에 사용하였습니다.\n",
    "\n",
    "\n",
    "나머지 복잡한 부분들(특히 forward의 리턴값이 x가 아니라 튜플인 점)은 혹시라도 실시간 처리에 사용하게 될 경우, LSTM들의 hidden state를 보존하여 이전 입력 프레임들을 매번 다시 주는 대신, 이전 입력 프레임들을 받고 나온 hidden state와 새 프레임 정보들만을 주어도 현재의 수상함?을 판단할 수 있게 하기 위해서입니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([299, 1])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sX2=next(sample_forever(gumaes2,10))\n",
    "mymodel_jit(sX2)[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigruns=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.utils.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from typing import NamedTuple\n",
    "import tqdm\n",
    "\n",
    "class TrainResult(NamedTuple):\n",
    "    loss_train:torch.Tensor\n",
    "    accuracy_train:torch.Tensor\n",
    "    loss_test:torch.Tensor\n",
    "    accuracy_test:torch.Tensor\n",
    "\n",
    "\n",
    "def train_step(model:mynn.RNNthenSequential,forward,optim:torch.optim.Optimizer,\n",
    "               #sample_train,sample_test\n",
    "               gtrain,gtest,jtrain,jtest,w_g,need_stat:bool\n",
    "               )->TrainResult:\n",
    "    model.train()\n",
    "    g_pred,_=forward(gtrain)\n",
    "    j_pred,_=forward(jtrain)\n",
    "    #sX,sy=sample_train\n",
    "    #train_pred,_=model(sX)\n",
    "\n",
    "    #loss:torch.Tensor=((train_pred-sy)**2).mean()\n",
    "    loss=get_loss(g_pred,j_pred,w_g)\n",
    "\n",
    "    #writer.add_scalar(\"Loss/train\", loss, step)\n",
    "        \n",
    "    optim.zero_grad()\n",
    "    loss.backward()\n",
    "    optim.step()\n",
    "    if not need_stat:\n",
    "        return\n",
    "    with torch.no_grad():\n",
    "        #acc=torch.mean((train_pred>0.5)==(sy>0.5),dtype=torch.float32)\n",
    "        acc=get_acc(g_pred,j_pred,w_g)\n",
    "\n",
    "        #tX,ty=sample_test\n",
    "        #test_pred,_=model(tX)\n",
    "        #loss_test=((test_pred-ty)**2).mean()\n",
    "        #accuracy_test=torch.mean((test_pred>0.5)==(ty>0.5),dtype=torch.float32)\n",
    "        model.eval()\n",
    "        G,_=forward(gtest)\n",
    "        J,_=forward(jtest)\n",
    "        loss_test=get_loss(G,J,w_g)\n",
    "        accuracy_test=get_acc(G,J,w_g)\n",
    "\n",
    "\n",
    "\n",
    "        return TrainResult(\n",
    "            loss_train=loss,\n",
    "            accuracy_train=acc,\n",
    "            loss_test=loss_test,\n",
    "            accuracy_test=accuracy_test\n",
    "        )\n",
    "\n",
    "\n",
    "def train_once(model,forward,optim,\n",
    "               #data_train,data_test,\n",
    "               gumae_train,gumae_test,juldo_test,juldo_train,\n",
    "               run=1,n_sample=70,epochs=200,n_test_sample=50,mix_min=0.3,mix_max=0.5):\n",
    "    writer = SummaryWriter(f'logs/v0/runs-{bigruns}-{run}')\n",
    "    #as_sampler=lambda data,batchsize:forever(torch.utils.data.DataLoader(data,batchsize,shuffle=True,drop_last=True))\n",
    "    \n",
    "\n",
    "    #train_it=sample_forever(data_train,n_sample)\n",
    "    #test_it=sample_forever(data_test,n_train_sample)\n",
    "    its=list(map(sample_forever,(gumae_train,gumae_test,juldo_train,juldo_test),\n",
    "                                                                 (n_sample,n_test_sample,n_sample,n_test_sample)))\n",
    "    assert len(its)==4\n",
    "    #assert len([*map(next,its)])==4\n",
    "    for step in tqdm.tqdm(range(epochs)):\n",
    "        mix=random.random()*mix_max+mix_min\n",
    "        mix=torch.tensor((mix,),device=device)#\n",
    "\n",
    "\n",
    "        result=train_step(model,forward,optim,*map(next,its),w_g=mix,need_stat=step%5==0)\n",
    "        if result is not None:\n",
    "            writer.add_scalar(\"Loss/train\", result.loss_train, step)\n",
    "            writer.add_scalar(\"Accuracy/train\", result.accuracy_train, step)\n",
    "            writer.add_scalar(\"Loss/test\",result.loss_test,step)\n",
    "            writer.add_scalar(\"Accuracy/test\",result.accuracy_test,step)\n",
    "        if step%30==0:\n",
    "            writer.flush()\n",
    "\n",
    "    writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "훈련 상황을 실시간으로 확인하기 위해 tensorboard를 사용하였습니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/200 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:36<00:00,  5.53it/s]\n",
      "100%|██████████| 200/200 [00:35<00:00,  5.64it/s]\n",
      "100%|██████████| 200/200 [00:35<00:00,  5.66it/s]\n",
      "100%|██████████| 200/200 [00:35<00:00,  5.68it/s]\n",
      "100%|██████████| 200/200 [00:34<00:00,  5.77it/s]\n",
      "100%|██████████| 200/200 [00:34<00:00,  5.84it/s]\n",
      "100%|██████████| 200/200 [00:34<00:00,  5.84it/s]\n",
      "100%|██████████| 200/200 [00:34<00:00,  5.78it/s]\n",
      "100%|██████████| 200/200 [00:34<00:00,  5.80it/s]\n",
      "100%|██████████| 200/200 [00:34<00:00,  5.87it/s]\n"
     ]
    }
   ],
   "source": [
    "bigruns+=1\n",
    "\n",
    "for i in range(10):\n",
    "    train_once(mymodel,mymodel.forward,optim,\n",
    "               gumae_train=gumae_train,gumae_test=gumae_test,juldo_test=juldo_test,juldo_train=juldo_train\n",
    "               #data_train=data_train,data_test=data_test\n",
    "               ,run=i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "바로 위의 블록을 실행하면 훈련이 진행되고, 이 블록 자체를 여러번 실행할 것을 염두에 두었기에 전역변수인 bigruns가 이 블록의 실행 회수를 기억하게 하였습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`pip install tensorboard`\n",
    "`python -m tensorboard --logdir {path_to_log} `\n",
    "\n",
    "로 방금 `logs/v0/runs-{bigruns}-{run}`에 저장한 로그들을 읽을 수 있습니다.\n",
    "실행 결과를 보자면 loss도 accuracy도 수렴할 조짐 자체를 아예 보이지 않고 있습니다.\n",
    "\n",
    "거기에 혹시 tensorboard를 실행할 수 없는 환경이라면 제가 직접 `logs_svg/v0` 에 tensorboard에서 볼 수 있는 그래프를 .svg로 저장해두었습니다.\n",
    "\n",
    "`logs_svg/v0/Loss_train.svg` 만 보더라도 전혀 감소하는 기색을 보이지 않고 있습니다...\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

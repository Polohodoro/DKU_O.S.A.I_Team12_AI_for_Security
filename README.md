# DKU_Team12_AI_for_Security
AI for Security Recognition in Unmanned Stores

## 개요
무인 상점의 보안을 위한, 동작 인식 AI를 만들고자 하였습니다.

## 전처리
파일: 전처리_코드(수정)_ipynb의_사본.ipynb  

https://github.com/misbah4064/human-pose-estimation-opencv.git

해당 링크의 'human-pose-estimation-opencv'를 활용하여 영상 데이터에서 사람의 움직임을 포착하고, 해당 움직임을 프레임으로 추출합니다.

![KakaoTalk_20231221_202434154](https://github.com/Polohodoro/DKU_Team12_AI-_for_Security/assets/152270465/55f59f5c-4fe6-4c1e-bdd7-4b08681b4d63)

세부 내용은 해당 파일을 클릭해 확인할 수 있습니다.

## AI모델 구현 및 훈련
파일: ral_v0_verbose.ipynb  

데이터 로드, 모델 작성 등 전반적인 부분에 대해 다루고 있습니다.

세부 내용은 해당 파일을 클릭해 확인할 수 있습니다.

##  패키지 정보

absl-py==2.0.0<br>
asttokens==2.4.1<br>
cachetools==5.3.2<br>
certifi==2023.11.17<br>
charset-normalizer==3.3.2<br>
colorama==0.4.6<br>
comm==0.2.0<br>
debugpy==1.8.0<br>
decorator==5.1.1<br>
executing==2.0.1<br>
filelock==3.9.0<br>
fsspec==2023.4.0<br>
google-auth==2.25.1<br>
google-auth-oauthlib==1.1.0<br>
grpcio==1.60.0<br>
idna==3.6<br>
ipykernel==6.27.1<br>
ipython==8.18.1<br>
jedi==0.19.1<br>
Jinja2==3.1.2<br>
jupyter_client==8.6.0<br>
jupyter_core==5.5.0<br>
Markdown==3.5.1<br>
MarkupSafe==2.1.3<br>
matplotlib-inline==0.1.6<br>
mpmath==1.3.0<br>
nest-asyncio==1.5.8<br>
networkx==3.0<br>
numpy==1.26.2<br>
oauthlib==3.2.2<br>
packaging==23.2<br>
pandas==2.1.3<br>
parso==0.8.3<br>
platformdirs==4.1.0<br>
prompt-toolkit==3.0.41<br>
protobuf==4.23.4<br>
psutil==5.9.6<br>
pure-eval==0.2.2<br>
pyasn1==0.5.1<br>
pyasn1-modules==0.3.0<br>
Pygments==2.17.2<br>
python-dateutil==2.8.2<br>
pytz==2023.3.post1<br>
pywin32==306<br>
pyzmq==25.1.2<br>
requests==2.31.0<br>
requests-oauthlib==1.3.1<br>
rsa==4.9<br>
six==1.16.0<br>
stack-data==0.6.3<br>
sympy==1.12<br>
tensorboard==2.15.1<br>
tensorboard-data-server==0.7.2<br>
torch==2.1.1+cu118<br>
torch-tb-profiler==0.4.3<br>
tornado==6.4<br>
tqdm==4.66.1<br>
traitlets==5.14.0<br>
typing_extensions==4.4.0<br>
tzdata==2023.3<br>
urllib3==2.1.0<br>
wcwidth==0.2.12<br>
Werkzeug==3.0.1<br>

## 파이썬 버전

## 설치한 라이브러리

## 실행 방법



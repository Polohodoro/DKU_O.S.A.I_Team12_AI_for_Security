{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Polohodoro/DKU_Team12_AI-_for_Security/blob/main/%EC%A0%84%EC%B2%98%EB%A6%AC_%EC%BD%94%EB%93%9C(%EC%88%98%EC%A0%95)_ipynb%EC%9D%98_%EC%82%AC%EB%B3%B8.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m90ftGDEMZND",
        "outputId": "539a313a-ea5e-4c98-e8c6-877f03af793d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'human-pose-estimation-opencv' already exists and is not an empty directory.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/misbah4064/human-pose-estimation-opencv.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cAtA-4qsBYgE",
        "outputId": "1e4d0746-c8c0-4d6c-e972-6959358584d9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/human-pose-estimation-opencv\n"
          ]
        }
      ],
      "source": [
        "%cd human-pose-estimation-opencv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IgSuGRapBZpj",
        "outputId": "27c9f0ee-e175-4cef-eb7c-18a4d6997a29"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OaIm2za5BbEb"
      },
      "outputs": [],
      "source": [
        "import cv2 as cv\n",
        "import numpy as np\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "def cal_angle(point1, point2): #  단위벡터 구하기\n",
        "    diff = np.array(point2) - np.array(point1)\n",
        "    vector = np.linalg.norm(diff)\n",
        "\n",
        "    if vector != 0:\n",
        "        vector = diff / vector\n",
        "    else:\n",
        "        vector = np.zeros_like(diff)\n",
        "    return vector[0],vector[1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7L5VYAFMCafb"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "def get_video_files(directory_path):\n",
        "    video_files = [f for f in os.listdir(directory_path) if f.endswith(('.mp4'))]\n",
        "    video_files.sort()  # 파일을 정렬하려면 사용\n",
        "    return video_files\n",
        "\n",
        "# Google Drive 내의 디렉토리 경로 설정\n",
        "path = \"/content/drive/MyDrive/영상폴더/구매\"\n",
        "\n",
        "# 비디오 파일 목록 가져오기\n",
        "video_files = get_video_files(path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3hCTe34EDpOK"
      },
      "outputs": [],
      "source": [
        "import cv2 as cv\n",
        "import numpy as np\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "BODY_PARTS = { \"Nose\": 0, \"Neck\": 1, \"RShoulder\": 2, \"RElbow\": 3, \"RWrist\": 4,\n",
        "               \"LShoulder\": 5, \"LElbow\": 6, \"LWrist\": 7, \"RHip\": 8, \"RKnee\": 9,\n",
        "               \"RAnkle\": 10, \"LHip\": 11, \"LKnee\": 12, \"LAnkle\": 13, \"REye\": 14,\n",
        "               \"LEye\": 15, \"REar\": 16, \"LEar\": 17, \"Background\": 18 }\n",
        "\n",
        "# 내적값을 구할 관절 모음\n",
        "# 필요없다고 판단한 얼굴부분 좌표는 제외시켰습니다.\n",
        "POSE_PAIRS = [ [\"Neck\", \"RShoulder\"], [\"Neck\", \"LShoulder\"], [\"RShoulder\", \"RElbow\"],\n",
        "               [\"RElbow\", \"RWrist\"], [\"LShoulder\", \"LElbow\"], [\"LElbow\", \"LWrist\"],\n",
        "               [\"Neck\", \"RHip\"], [\"RHip\", \"RKnee\"], [\"RKnee\", \"RAnkle\"], [\"Neck\", \"LHip\"],\n",
        "               [\"LHip\", \"LKnee\"], [\"LKnee\", \"LAnkle\"] ]\n",
        "\n",
        "width = 368\n",
        "height = 368\n",
        "inWidth = width\n",
        "inHeight = height\n",
        "\n",
        "net = cv.dnn.readNetFromTensorflow(\"graph_opt.pb\")\n",
        "thr = 0.2\n",
        "\n",
        "def poseDetector(frame):\n",
        "    frameWidth = frame.shape[1]\n",
        "    frameHeight = frame.shape[0]\n",
        "\n",
        "    net.setInput(cv.dnn.blobFromImage(frame, 1.0, (inWidth, inHeight), (127.5, 127.5, 127.5), swapRB=True, crop=False))\n",
        "    out = net.forward()\n",
        "    out = out[:, :19, :, :]  # MobileNet output [1, 57, -1, -1], we only need the first 19 elements\n",
        "\n",
        "    assert(len(BODY_PARTS) == out.shape[1])\n",
        "\n",
        "    points = []\n",
        "    for i in range(len(BODY_PARTS)):\n",
        "        heatMap = out[0, i, :, :]\n",
        "        _, conf, _, point = cv.minMaxLoc(heatMap)\n",
        "        x = (frameWidth * point[0]) / out.shape[3]\n",
        "        y = (frameHeight * point[1]) / out.shape[2]\n",
        "        points.append((int(x), int(y)) if conf > thr else None)\n",
        "\n",
        "    angles = []\n",
        "    for pair in POSE_PAIRS:\n",
        "        partFrom = pair[0]\n",
        "        partTo = pair[1]\n",
        "        assert(partFrom in BODY_PARTS)\n",
        "        assert(partTo in BODY_PARTS)\n",
        "\n",
        "        idFrom = BODY_PARTS[partFrom]\n",
        "        idTo = BODY_PARTS[partTo]\n",
        "        if points[idFrom] and points[idTo]:\n",
        "            p_x,p_y = cal_angle(points[idFrom], points[idTo])\n",
        "            joint_angles = {f'{partFrom}-{partTo}-x': p_x ,f'{partFrom}-{partTo}-y': p_y }\n",
        "            angles.append(joint_angles)\n",
        "        else:\n",
        "            angles.append({f'{partFrom}-{partTo}-x': 0.0,f'{partFrom}-{partTo}-y':0.0})\n",
        "\n",
        "    t, _ = net.getPerfProfile()\n",
        "\n",
        "    # 관절 좌표 반환\n",
        "    return frame, angles"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iWPkD4aSFvwl"
      },
      "source": [
        "일반 구매 데이터"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V5rChFWjDLFx",
        "outputId": "0b707f50-2a28-4896-f1bb-0c0f60563699"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "C_2_2_57_BU_DYB_10-20_13-59-11_CA_RGB_DF1_M4_M4.mp4\n",
            "pass\n",
            "C_2_2_57_BU_DYB_10-20_13-59-11_CB_RGB_DF1_M4_M4.mp4\n",
            "pass\n",
            "C_2_2_57_BU_DYB_10-20_13-59-11_CC_RGB_DF1_M4_M4.mp4\n",
            "pass\n",
            "C_2_2_57_BU_DYB_10-20_13-59-11_CD_RGB_DF1_M4_M4.mp4\n",
            "pass\n",
            "C_2_2_57_BU_SMA_09-16_10-05-32_CC_RGB_DF1_F3_F3.mp4\n",
            "pass\n",
            "C_2_2_57_BU_SMA_09-16_10-05-33_CA_RGB_DF1_F3_F3.mp4\n",
            "pass\n",
            "C_2_2_57_BU_SMA_09-16_10-05-33_CB_RGB_DF1_F3_F3.mp4\n",
            "pass\n",
            "C_2_2_57_BU_SMB_10-15_15-56-14_CA_RGB_DF1_F3_F3.mp4\n",
            "pass\n",
            "C_2_2_57_BU_SMB_10-15_15-56-14_CB_RGB_DF1_F3_F3.mp4\n",
            "pass\n",
            "C_2_2_57_BU_SMB_10-15_15-56-14_CC_RGB_DF1_F3_F3.mp4\n",
            "pass\n",
            "C_2_2_57_BU_SMB_10-15_15-56-14_CD_RGB_DF1_F3_F3.mp4\n",
            "pass\n",
            "C_2_2_57_BU_SYA_09-15_10-48-45_CA_RGB_DF1_F3_F3.mp4\n",
            "pass\n",
            "C_2_2_57_BU_SYA_09-15_10-48-45_CB_RGB_DF1_F3_F3.mp4\n",
            "pass\n",
            "C_2_2_57_BU_SYA_09-15_10-48-45_CC_RGB_DF1_F3_F3.mp4\n",
            "pass\n",
            "C_2_2_57_BU_SYB_10-15_17-33-01_CA_RGB_DF1_F3_F3.mp4\n",
            "pass\n",
            "C_2_2_57_BU_SYB_10-15_17-33-01_CB_RGB_DF1_F3_F3.mp4\n",
            "pass\n",
            "C_2_2_57_BU_SYB_10-15_17-33-01_CC_RGB_DF1_F3_F3.mp4\n",
            "pass\n",
            "C_2_2_57_BU_SYB_10-15_17-33-01_CD_RGB_DF1_F3_F3.mp4\n",
            "pass\n",
            "C_2_2_58_BU_DYB_10-20_14-00-58_CA_RGB_DF1_M4_M4.mp4\n",
            "pass\n",
            "C_2_2_58_BU_DYB_10-20_14-00-58_CB_RGB_DF1_M4_M4.mp4\n",
            "pass\n",
            "C_2_2_58_BU_DYB_10-20_14-00-58_CC_RGB_DF1_M4_M4.mp4\n",
            "pass\n",
            "C_2_2_58_BU_DYB_10-20_14-00-58_CD_RGB_DF1_M4_M4.mp4\n",
            "pass\n",
            "C_2_2_59_BU_DYB_10-20_14-02-41_CA_RGB_DF1_M4_M4.mp4\n",
            "pass\n",
            "C_2_2_59_BU_DYB_10-20_14-02-41_CB_RGB_DF1_M4_M4.mp4\n",
            "pass\n",
            "C_2_2_59_BU_DYB_10-20_14-02-41_CC_RGB_DF1_M4_M4.mp4\n",
            "pass\n",
            "C_2_2_59_BU_DYB_10-20_14-02-41_CD_RGB_DF1_M4_M4.mp4\n",
            "pass\n",
            "C_2_2_59_BU_SMA_09-16_10-07-19_CB_RGB_DF1_F3_F3.mp4\n",
            "pass\n",
            "C_2_2_59_BU_SMA_09-16_10-07-19_CC_RGB_DF1_F3_F3.mp4\n",
            "pass\n",
            "C_2_2_59_BU_SMA_09-16_10-07-19_CD_RGB_DF1_F3_F3.mp4\n",
            "pass\n",
            "C_2_2_59_BU_SMA_09-16_10-07-20_CA_RGB_DF1_F3_F3.mp4\n",
            "pass\n",
            "C_2_2_59_BU_SMB_10-15_15-57-35_CA_RGB_DF1_F3_F3.mp4\n",
            "pass\n",
            "C_2_2_59_BU_SMB_10-15_15-57-35_CB_RGB_DF1_F3_F3.mp4\n",
            "pass\n",
            "C_2_2_59_BU_SMB_10-15_15-57-35_CC_RGB_DF1_F3_F3.mp4\n",
            "pass\n",
            "C_2_2_59_BU_SMB_10-15_15-57-35_CD_RGB_DF1_F3_F3.mp4\n",
            "pass\n",
            "C_2_2_59_BU_SYA_09-15_10-50-47_CA_RGB_DF1_F3_F3.mp4\n",
            "pass\n",
            "C_2_2_59_BU_SYA_09-15_10-50-47_CB_RGB_DF1_F3_F3.mp4\n",
            "pass\n",
            "C_2_2_59_BU_SYA_09-15_10-50-47_CC_RGB_DF1_F3_F3.mp4\n",
            "pass\n",
            "C_2_2_59_BU_SYA_09-15_10-50-47_CD_RGB_DF1_F3_F3.mp4\n",
            "pass\n",
            "C_2_2_59_BU_SYB_10-15_17-34-57_CA_RGB_DF1_F3_F3.mp4\n",
            "pass\n",
            "C_2_2_59_BU_SYB_10-15_17-34-57_CB_RGB_DF1_F3_F3.mp4\n",
            "pass\n",
            "C_2_2_59_BU_SYB_10-15_17-34-57_CC_RGB_DF1_F3_F3.mp4\n",
            "pass\n",
            "C_2_2_59_BU_SYB_10-15_17-34-57_CD_RGB_DF1_F3_F3.mp4\n",
            "pass\n",
            "C_2_2_60_BU_DYB_10-20_14-04-13_CA_RGB_DF1_M4_M4.mp4\n",
            "pass\n",
            "C_2_2_60_BU_DYB_10-20_14-04-13_CB_RGB_DF1_M4_M4.mp4\n",
            "pass\n",
            "C_2_2_60_BU_DYB_10-20_14-04-13_CC_RGB_DF1_M4_M4.mp4\n",
            "pass\n",
            "C_2_2_60_BU_DYB_10-20_14-04-13_CD_RGB_DF1_M4_M4.mp4\n",
            "pass\n",
            "C_2_2_60_BU_SMA_09-16_15-59-50_CB_RGB_DF1_M4_M4.mp4\n",
            "pass\n",
            "C_2_2_60_BU_SMA_09-16_15-59-50_CC_RGB_DF1_M4_M4.mp4\n",
            "pass\n",
            "C_2_2_60_BU_SMA_09-16_15-59-51_CA_RGB_DF1_M4_M4.mp4\n",
            "pass\n",
            "C_2_2_60_BU_SMA_09-16_15-59-51_CD_RGB_DF1_M4_M4.mp4\n",
            "pass\n",
            "C_2_2_60_BU_SMB_10-15_10-55-43_CA_RGB_DF1_M4_M4.mp4\n",
            "pass\n",
            "C_2_2_60_BU_SMB_10-15_10-55-43_CB_RGB_DF1_M4_M4.mp4\n",
            "pass\n",
            "C_2_2_60_BU_SMB_10-15_10-55-43_CC_RGB_DF1_M4_M4.mp4\n",
            "pass\n",
            "C_2_2_60_BU_SMB_10-15_10-55-43_CD_RGB_DF1_M4_M4.mp4\n",
            "pass\n",
            "C_2_2_60_BU_SYA_09-16_14-02-44_CA_RGB_DF1_M4_M4.mp4\n",
            "pass\n",
            "C_2_2_60_BU_SYA_09-16_14-02-44_CB_RGB_DF1_M4_M4.mp4\n",
            "pass\n",
            "C_2_2_60_BU_SYA_09-16_14-02-44_CC_RGB_DF1_M4_M4.mp4\n",
            "pass\n",
            "C_2_2_60_BU_SYA_09-16_14-02-44_CD_RGB_DF1_M4_M4.mp4\n",
            "pass\n",
            "C_2_2_60_BU_SYB_10-15_09-59-03_CA_RGB_DF1_M4_M4.mp4\n",
            "pass\n",
            "C_2_2_60_BU_SYB_10-15_09-59-03_CB_RGB_DF1_M4_M4.mp4\n",
            "pass\n",
            "C_2_2_60_BU_SYB_10-15_09-59-03_CD_RGB_DF1_M4_M4.mp4\n",
            "pass\n",
            "C_2_2_61_BU_SMA_09-16_16-01-29_CC_RGB_DF1_M4_M4.mp4\n",
            "pass\n",
            "C_2_2_61_BU_SMA_09-16_16-01-30_CA_RGB_DF1_M4_M4.mp4\n",
            "pass\n",
            "C_2_2_61_BU_SMA_09-16_16-01-30_CB_RGB_DF1_M4_M4.mp4\n",
            "pass\n",
            "C_2_2_61_BU_SMA_09-16_16-01-30_CD_RGB_DF1_M4_M4.mp4\n",
            "pass\n",
            "C_2_2_61_BU_SMB_10-15_10-58-58_CA_RGB_DF1_M4_M4.mp4\n",
            "pass\n",
            "C_2_2_61_BU_SMB_10-15_10-58-58_CB_RGB_DF1_M4_M4.mp4\n",
            "pass\n",
            "C_2_2_61_BU_SMB_10-15_10-58-58_CC_RGB_DF1_M4_M4.mp4\n",
            "Processing Video...\n",
            "C_2_2_61_BU_SMB_10-15_10-58-58_CD_RGB_DF1_M4_M4.mp4\n",
            "Processing Video...\n",
            "C_2_2_61_BU_SYA_09-16_14-04-18_CA_RGB_DF1_M4_M4.mp4\n",
            "Processing Video...\n",
            "C_2_2_61_BU_SYA_09-16_14-04-18_CB_RGB_DF1_M4_M4.mp4\n",
            "Processing Video...\n",
            "C_2_2_61_BU_SYA_09-16_14-04-18_CC_RGB_DF1_M4_M4.mp4\n",
            "Processing Video...\n"
          ]
        }
      ],
      "source": [
        "import cv2\n",
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "for file_name in video_files  :\n",
        " print(file_name)\n",
        " if not(f\"{file_name}_1.pkl\" in os.listdir(\"/content/drive/MyDrive/영상폴더/구매(수정)\")):\n",
        "  cap = cv2.VideoCapture(f\"{path}/{file_name}\")\n",
        "  ret, frame = cap.read()\n",
        "  frame_height, frame_width, _ = frame.shape\n",
        "  out = cv2.VideoWriter('output.avi',cv2.VideoWriter_fourcc('M','J','P','G'), 10, (frame_width,frame_height))\n",
        "  print(\"Processing Video...\")\n",
        "  coors = []\n",
        "  angles = []\n",
        "  while cap.isOpened():\n",
        "    ret, frame = cap.read()\n",
        "    if not ret:\n",
        "      out.release()\n",
        "      break\n",
        "\n",
        "    output,angle = poseDetector(frame)\n",
        "    an = {}\n",
        "    for item in angle:\n",
        "      an.update(item)\n",
        "    angles.append(an)\n",
        "  df = pd.DataFrame(angles)\n",
        "  df = df.fillna(0.0)\n",
        "  total_rows = len(df)\n",
        "  half_rows = total_rows // 2\n",
        "  df1 = df.head(half_rows)\n",
        "  df2 = df.tail(half_rows)\n",
        "\n",
        "  df1.to_pickle(f\"/content/drive/MyDrive/영상폴더/구매(수정)/{file_name}_1.pkl\")\n",
        "  df2.to_pickle(f\"/content/drive/MyDrive/영상폴더/구매(수정)/{file_name}_2.pkl\")\n",
        " else:\n",
        "  print(\"pass\")\n",
        "print(\"Done\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "절도 데이터 (구매데이터 추출과 동일함)"
      ],
      "metadata": {
        "id": "l_Jf_C0qOrRs"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZO9Zmp8qOtSm"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "def get_video_files(directory_path):\n",
        "    video_files = [f for f in os.listdir(directory_path) if f.endswith(('.mp4'))]\n",
        "    video_files.sort()  # 파일을 정렬하려면 사용\n",
        "    return video_files\n",
        "\n",
        "# Google Drive 내의 디렉토리 경로 설정\n",
        "path = \"/content/drive/MyDrive/영상폴더/절도\"\n",
        "\n",
        "# 비디오 파일 목록 가져오기\n",
        "video_files = get_video_files(path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I3bNbRQkOtSn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f16e3c91-fdd4-4cfe-a133-2e10aa858605"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "C_3_12_10_BU_DYA_07-27_13-01-22_CA_RGB_DF2_F2.mp4\n",
            "Processing Video...\n",
            "C_3_12_10_BU_DYA_07-27_13-01-25_CB_RGB_DF2_F2.mp4\n",
            "Processing Video...\n",
            "C_3_12_10_BU_DYA_07-27_13-01-25_CC_RGB_DF2_F2.mp4\n",
            "Processing Video...\n",
            "C_3_12_10_BU_DYA_08-10_14-54-42_CD_RGB_DF2_M2.mp4\n",
            "Processing Video...\n",
            "C_3_12_10_BU_DYA_08-10_14-54-47_CE_RGB_DF2_M2.mp4\n",
            "Processing Video...\n",
            "C_3_12_10_BU_DYA_08-10_14-54-47_CF_RGB_DF2_M2.mp4\n",
            "Processing Video...\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-772fe6ca3ac6>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m       \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m     \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mangle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mposeDetector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m     \u001b[0man\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mangle\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-5-78ce0451f1e5>\u001b[0m in \u001b[0;36mposeDetector\u001b[0;34m(frame)\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetInput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblobFromImage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minWidth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minHeight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m127.5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m127.5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m127.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mswapRB\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcrop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m     \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m     \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;36m19\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# MobileNet output [1, 57, -1, -1], we only need the first 19 elements\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "import cv2\n",
        "import pandas as pd\n",
        "\n",
        "for file_name in video_files  :\n",
        " print(file_name)\n",
        " if not(f\"{file_name}.pkl\" in os.listdir(\"/content/drive/MyDrive/영상폴더/절도(수정)\")):\n",
        "  cap = cv2.VideoCapture(f\"{path}/{file_name}\")\n",
        "  ret, frame = cap.read()\n",
        "  frame_height, frame_width, _ = frame.shape\n",
        "  out = cv2.VideoWriter('output.avi',cv2.VideoWriter_fourcc('M','J','P','G'), 10, (frame_width,frame_height))\n",
        "  print(\"Processing Video...\")\n",
        "  coors = []\n",
        "  angles = []\n",
        "  while cap.isOpened():\n",
        "    ret, frame = cap.read()\n",
        "    if not ret:\n",
        "      out.release()\n",
        "      break\n",
        "\n",
        "    output,angle = poseDetector(frame)\n",
        "    an = {}\n",
        "    for item in angle:\n",
        "      an.update(item)\n",
        "    angles.append(an)\n",
        "  df = pd.DataFrame(angles)\n",
        "  df = df.fillna(0.0)\n",
        "  df.to_pickle(f\"/content/drive/MyDrive/영상폴더/절도(수정)/{file_name}.pkl\")\n",
        " else:\n",
        "  print(\"pass\")\n",
        "print(\"Done\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "m3S5ZjKILQul"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}